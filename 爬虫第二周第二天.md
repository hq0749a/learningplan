## **第二天:** 

导言:了解Scrapy框架中Middleware中间件和Pipeline管道文件的使用原理,完成第一个Scrapy异步抓取的实战项目.

## **课程小节:**  

1>Middleware中间件

2> Pipeline管道文件

3>Scrapy异步抓取实战

## **章节三 第三节 Middleware中间件:**

​    知识要点:

​        1> 着重了解DownloadMiddleware类方法的定义方式,引入方式和使用方法.

​        2> 了解DownloadMiddleware类方法中每个方法的作用和使用场景.

​        3> 重点掌握DownloadMiddleware中间件中process_request的代理IP设置方式.

​        4> 掌握 start.py的启动爬虫文件的方法, 也可以cd到spider下 使用命令行来启动爬虫文件.

## **章节三 第四节 Pipeline管道文件:**

​    知识要点:

​    1>明确调用Pipeline管道文件的使用场景:当spider文件yield的数据类型是字典时,就会调用管道文件.

​    2>在设置优先级时,数字越小,表示优先级越高,优先执行.

​    3>爬虫文件所有数据处理,全部在管道文件中使用process_item来进行数据的处理和保存.

## **章节三 第五节 Scrapy异步抓取实战:**

​    知识要点:

​        1>根据视频,使用scrapy框架实现CSDN热门帖子抓取的案例.

​        2>将之前学习的scrapy的创建命令,Xpath数据解析,爬虫文件的启动方式等通过该案例进行融会贯通.

​        3>在使用xpath获取数据时,注意一下extract()和extract_first()方法的区别:

​            extract()返回的是一个列表,而extract_first()返回的是相应数据的的第一个值.

​        4>在运行爬虫文件之前,必须开启settings中的DOWNLOAD_DELAY并降低属性值,以达到降低访问频率的效果.