##### **第四天:** 

导言:了解Scrapy的异常请求的处理机制,熟练使用深拷贝在spider中的各个方法之间进行数据的重复异步调用,.

##### **课程小节:**  

1>异常请求的处理机制

2> 请求链的健壮性优化

3>异步IO实现数据持久化存储

##### **章节四 第四节** **异常请求的处理机制****:**

​    知识要点:

​        1>中间件中使用Exception处理.

​        2>在开发中,更多的是使用Scrapy的Log日志来进行异常信息的记录,熟练使用log日志的配置方式,一般我们使用的是error级别的设置.

##### **章节四 第五节** **请求链的健壮性优化****:**

​    知识要点:

​        1>了解2种请求链的优缺点.

​        2>通过start_requsets方法发送的request请求可以跳过爬虫文件中allowed_domains的限制来发送请求.

​        3>使用深拷贝来实现同一个数据的多次异步调用,

​        4>当前方法想用到调用上一次的formdata内容,需要做以下步骤:

​            1>将上一次的formdata内容赋值到request.meta['form_data']中.

​            2> 在当前方法中对reponse.meta['form_data']进行深拷贝,就可以实现调用了.

​        5>本节课程内容较多,需要同学们反复认真的看,根据视频中的方法,实现案例的代码并测试效果.

##### **章节四 第六节** **异步IO实现数据持久化存储****:**	

​    知识要点:

​        1>使用pip install pymysql 安装pymysql模块,练习基本的mysql数据的连接和SQL语句的执行.

​        2>使用pipeline+pymysql 进行数据的数据库存储.

​        3>根据视频,在pipeline中列表表达式和占位符来组装sql语句,并执行.