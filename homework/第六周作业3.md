# 第六周作业3

## 1 作业描述 

将Scrapy抓取必联网项目升级为Scrapy‐Redis分布式爬虫，并完成代理IP池proxyPool的开发 

1. 完成Scrapy‐Redis组件的安装 

2. 完成代理IP池proxyPool的开发 

3. 将必联网爬虫项目升级为Scapy‐Redis分布式爬虫 

4. 分布式爬虫在中间件中设置代理要通过代理IP池来获取，而不是每次请求都访问第三方代理IP 接口 

## 2 解题提示

1. 普通的Scrapy项目升级升Scarpy‐Redis分布式爬虫，只需要在Settings中加入4局配置 

```pyton
# 启动Scrapy‐Redis去重过滤器，取消Scrapy的去重功能 
DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDupeFilter" 

# 启用Scrapy‐Redis的调度器，取消Scrapy的调度器 
SCHEDULER = "scrapy_redis.scheduler.Scheduler" 

# Scrapy‐Redis断点续爬 
SCHEDULER_PERSIST = True 

# 配置Redis数据库的连接 
REDIS_URL = 'redis://127.0.0.1:6379' 
```

2. 可以用Redis中的集合对象来存储第三方返回的代理IP地址，间隔时间访问第三方代理IP接口， 缓存记录上次的代理IP内容，当接口返回新的代理IP时，更新Redis中的数据 

## 3 评分标准

1. 完成Scrapy‐Redis的配置10分 

2. 代理Ip池的开发 10分 

3. 代码注释，规范10分

